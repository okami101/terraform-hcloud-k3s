terraform {
  required_providers {
    hcloud = {
      source = "hetznercloud/hcloud"
    }
  }
}

provider "hcloud" {
  # Here is the required hcloud API token with RW access in order to create all needed resources.
  token = "xxxxxx"
}

resource "hcloud_ssh_key" "default" {
  name       = "john"
  public_key = "ssh-ed25519 xxxxxx"
}

module "hcloud_k3s" {
  providers = {
    hcloud = hcloud
  }

  source = "okami101/k3s/hcloud"

  # Next all self-explanatory variables that you can customized. See https://registry.terraform.io/modules/okami101/k3s/hcloud/latest?tab=inputs for description.

  server_image    = "ubuntu-22.04"
  server_timezone = "Europe/Paris"
  server_locale   = "fr_FR.UTF-8"

  # Install nfs-common in order to have working nfs provisioners on kubernetes storage classes.
  server_packages = ["nfs-common"]

  # Use preferably something different than default 22.
  ssh_port = 2222

  # All hostname will use it as a prefix, aka <cluster_name>-worker-01, etc.
  cluster_name = "k3s"
  # The unix user for ssh login.
  cluster_user = "kube"

  # The above hcloud ssh key names for adding them when creating nodes.
  my_ssh_key_names = [hcloud_ssh_key.default.name]
  # Put your fixed public ip here, heavily recommended for protecting ssh and kube server api port access on bastion server, default to any.
  my_ip_addresses = ["0.0.0.0/0", "::/0"]

  # Use stable (production usage) or latest (staging usage).
  k3s_channel = "stable"

  # All advanced parameters for each kubelet, see https://kubernetes.io/docs/reference/command-line-tools-reference/kubelet/.
  kubelet_args = []

  # Add k3s server specific custom control plane configuration options here.
  # E.g to enable monitoring for etcd, proxy etc.
  # See this reference https://docs.k3s.io/cli/server
  # control_planes_custom_config = {
  #  tls-san                     = ["my.domain.com"]
  #  etcd-s3                     = true
  #  etcd-s3-endpoint            = "xxxxxx.r2.cloudflarestorage.com"
  #  etcd-s3-access-key          = "xxxxxx"
  #  etcd-s3-secret-key          = "xxxxxx"
  #  etcd-s3-bucket              = "xxxxxx"
  #  etcd-snapshot-schedule-cron = "0 0 * * *"
  #  etcd-expose-metrics = true,
  #  kube-scheduler-arg = "bind-address=0.0.0.0",
  #  kube-controller-manager-arg = "bind-address=0.0.0.0",
  #  kube-proxy-arg ="metrics-bind-address=0.0.0.0",
  #  secrets-encryption = true,
  # }

  control_planes = {
    # Type "hcloud server-type list" for choose
    server_type = "cx21"
    # Type "hcloud datacenter list" for choose
    location    = "nbg1"
    # In hetzner, private_interface is the interface name for private network, ens10 is the default one for intel nics, enp7s0 for amd nics.
    private_interface = "ens10"
    # The number of control planes. For HA with etcd, use an odd number, 1, 3, 5, etc. Note as the 1st control plane will be the default bastion server, and will be used as main entry for any SSH access to any nodes.
    count = 1
    labels = []
    # Use taints to prevent pods to be scheduled on control planes.
    taints = [
      "node-role.kubernetes.io/control-plane:NoSchedule"
    ]
    # When HA mode, associate controllers to a dedicated load balancer
    # Optional attribute, remove it to use controller ips directly
    lb_type = "lb11"
  }

  # Here is the worker nodes, categorized according to unique typology (defined as a pool) of servers, taints, etc.
  agent_nodepools = [
    {
      # Will define the final hostname, aka <cluster_name>-worker-01, etc.
      name              = "worker"
      server_type       = "cx21"
      location          = "nbg1"
      private_interface = "ens10"
      # You can use next optional attribute to define the range private IP index for the nodepool. It allows to move items in the list without breaking the IP range.
      private_ip_index  = 0
      # The number of nodes in this pool. The main parameter for autoscaling.
      count             = 3
      labels            = []
      # No taint, can accept any workloads.
      taints            = []
      # Associate nodepool to a dedicated load balancer (optional)
      lb_type           = "lb11"
    },
    {
      # Here is an example of a nodepool with a different server type, and a taint. Typically used for database oriented nodes.
      name              = "storage"
      server_type       = "cx21"
      location          = "nbg1"
      private_interface = "ens10"
      private_ip_index  = 1
      count             = 1
      labels = [
        "node.kubernetes.io/server-usage=storage"
      ]
      taints = [
        "node-role.kubernetes.io/storage:NoSchedule"
      ]
      # Set a volume size in GB (at least 10) if need a block volume on each node of this pool
      volume_size   = 20
      volume_format = "ext4"
    }
  ]
}

#
# Use next lines to enable load balancer services.
#

resource "hcloud_load_balancer_service" "ssh_service" {
  load_balancer_id = module.hcloud_k3s.lbs.worker.id
  protocol         = "tcp"
  listen_port      = 22
  destination_port = 22
}

resource "hcloud_load_balancer_service" "http_service" {
  load_balancer_id = module.hcloud_k3s.lbs.worker.id
  protocol         = "tcp"
  listen_port      = 80
  destination_port = 80
}

resource "hcloud_load_balancer_service" "https_service" {
  load_balancer_id = module.hcloud_k3s.lbs.worker.id
  protocol         = "tcp"
  listen_port      = 443
  destination_port = 443
  proxyprotocol    = true
}

#
# Use next lines if you plan to use certificates directly managed by Hetzner
# This will replace above http_service as well as https_service
#

# resource "hcloud_managed_certificate" "example" {
#   name         = "example"
#   domain_names = ["*.example.com", "example.com"]
# }

# resource "hcloud_load_balancer_service" "https_service" {
#   load_balancer_id = module.hcloud_k3s.lbs.worker.id
#   protocol         = "https"
#   listen_port      = 443
#   destination_port = 80
#   proxyprotocol    = true
#   http {
#     redirect_http = true
#     certificates  = [hcloud_managed_certificate.example.id]
#   }
#   health_check {
#     protocol = "http"
#     interval = 15
#     port     = 80
#     timeout  = 10
#     http {
#       status_codes = ["404"]
#       path         = "/"
#     }
#   }
# }

#
# Use next lines to enable dedicated load balancer for controllers when HA mode.
#

# resource "hcloud_load_balancer_service" "kube_service" {
#   load_balancer_id = module.hcloud_k3s.lbs.controller.id
#   protocol         = "tcp"
#   listen_port      = 6443
#   destination_port = 6443
# }

#
# Output ssh config for access
#

output "ssh_config" {
  value = module.hcloud_k3s.ssh_config
}
